import streamlit as st   
import pandas as pd      
import requests          
from dotenv import load_dotenv  
from openai import OpenAI       
import os

load_dotenv()            
client = OpenAI()        

# FastAPIã®URLï¼ˆRAGã§æ¤œç´¢ã™ã‚‹ /ask ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰
RAG_API_URL = "http://127.0.0.1:8000/ask"


st.set_page_config(page_title="AIãƒ‡ãƒ¼ã‚¿ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ¤– AIãƒ‡ãƒ¼ã‚¿ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
st.markdown("CSVã®è¦ç´„ãƒãƒ£ãƒƒãƒˆ ï¼† PDFæ¤œç´¢ãƒãƒ£ãƒƒãƒˆï¼ˆRAGå¯¾å¿œï¼‰")

if "messages" not in st.session_state:
    st.session_state["messages"] = []  

for msg in st.session_state["messages"]:
    st.chat_message(msg["role"]).markdown(msg["content"])

mode = st.radio(
    "ãƒ¢ãƒ¼ãƒ‰ã‚’é¸ã‚“ã§ãã ã•ã„ğŸ‘‡",
    ("CSVè¦ç´„ãƒãƒ£ãƒƒãƒˆ", "PDFæ¤œç´¢ãƒãƒ£ãƒƒãƒˆï¼ˆRAGï¼‰")
)

if mode == "CSVè¦ç´„ãƒãƒ£ãƒƒãƒˆ":

    uploaded_file = st.file_uploader("ğŸ“‚ CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["csv"])

    if uploaded_file:
        df = pd.read_csv(uploaded_file)
        summary_stats = df.describe().to_dict()
        sample_rows = df.head(3).to_dict(orient="records")
        if prompt := st.chat_input("ã“ã®ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šè¦ç´„ã—ã¦ / å¤‰åŒ–ã‚’æ•™ãˆã¦ï¼‰"):
            st.session_state["messages"].append({"role": "user", "content": prompt})
            st.chat_message("user").markdown(prompt)
            full_prompt = f"""
            ã‚ãªãŸã¯å„ªç§€ãªãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
            æ¬¡ã®CSVãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚
            â–¼çµ±è¨ˆé‡ï¼ˆdescribeï¼‰
            {summary_stats}
            â–¼ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆå…ˆé ­3è¡Œï¼‰
            {sample_rows}
            â–¼ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•
            {prompt}
            """

            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": full_prompt}],
                max_tokens=500
            )
            answer = response.choices[0].message.content
            st.session_state["messages"].append({"role": "assistant", "content": answer})
            st.chat_message("assistant").markdown(answer)
else:
    if prompt := st.chat_input("PDFã®å†…å®¹ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šåŒ—æµ·é“ã®ç®—æ•°ã®å¹³å‡å€¤ã¯ï¼Ÿï¼‰"):
        st.session_state["messages"].append({"role": "user", "content": prompt})
        st.chat_message("user").markdown(prompt)
        try:
            response = requests.post(RAG_API_URL, json={"query": prompt})
            answer = response.json().get("answer", "ã‚¨ãƒ©ãƒ¼: å›ç­”ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        except Exception as e:
            answer = f"ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}"
        st.session_state["messages"].append({"role": "assistant", "content": answer})
        st.chat_message("assistant").markdown(answer)
